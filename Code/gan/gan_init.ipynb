{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba90ad9-d33f-43fb-94b1-7f903c38b9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 11:25:36.318743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Reshape, BatchNormalization, Conv2D, Conv2DTranspose, Conv3D, Conv3DTranspose, LeakyReLU, Dropout, Flatten, AveragePooling2D, AveragePooling3D, UpSampling2D, UpSampling3D\n",
    "from tensorflow.keras import Sequential, Input, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import imageio, glob\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078a18b3-5665-4dd5-8907-83c58c74137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile1 = np.load('/gpfs/alpine/gen150/scratch/arjun2612/ORNL_Coding/Code/sars_mers_cov2_dataset/smc2_dataset.npz')\n",
    "smc2_trainset = npzfile1['train4D']\n",
    "smc2_valset = npzfile1['val4D']\n",
    "smc2_lt_onehot = npzfile1['ltoh']\n",
    "smc2_lv_onehot = npzfile1['lvoh']\n",
    "smc2_label_validation = npzfile1['labval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119f73f4-5ba4-4f3b-88de-cd181e1a0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile2 = np.load('/gpfs/alpine/gen150/scratch/arjun2612/ORNL_Coding/Code/hea_dataset/hea_dataset.npz')\n",
    "hea_trainset = npzfile2['train4D']\n",
    "hea_valset = npzfile2['val4D']\n",
    "hea_lt_onehot = npzfile2['ltoh']\n",
    "hea_lv_onehot = npzfile2['lvoh']\n",
    "hea_label_validation = npzfile2['labval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5fd244-eaee-479f-a98f-fcf501e6b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 11:25:38.533490: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-11 11:25:38.534361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-11 11:25:38.586354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-08-11 11:25:38.586383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-11 11:25:38.588983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-11 11:25:38.589061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-11 11:25:38.590023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-11 11:25:38.590278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-11 11:25:38.592440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-11 11:25:38.592982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-11 11:25:38.593096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-11 11:25:38.594661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-11 11:25:38.594965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-11 11:25:38.595944: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-11 11:25:38.596817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-08-11 11:25:38.596838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-11 11:25:38.596863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-11 11:25:38.596873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-11 11:25:38.596884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-11 11:25:38.596894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-11 11:25:38.596903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-11 11:25:38.596913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-11 11:25:38.596922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-11 11:25:38.598434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-11 11:25:38.598462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-11 11:25:39.083732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-11 11:25:39.083779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-08-11 11:25:39.083786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-08-11 11:25:39.086284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14759 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "\n",
    "generator.add(Conv2DTranspose(128, (3, 3), padding='same', input_shape=(24, 24, 1), activation=LeakyReLU())) # batch_size x 24 x 24 x 128\n",
    "generator.add(Conv2DTranspose(64, (3, 3), padding='same', activation=LeakyReLU())) # batch_size x 24 x 24 x 64\n",
    "generator.add(BatchNormalization())\n",
    "\n",
    "generator.add(Conv2DTranspose(32, (3, 3), padding='same', activation=LeakyReLU())) # batch_size x 24 x 24 x 64\n",
    "generator.add(Conv2DTranspose(16, (3, 3), padding='same', activation=LeakyReLU())) # batch_size x 24 x 24 x 64\n",
    "generator.add(BatchNormalization())\n",
    "\n",
    "generator.add(Conv2DTranspose(8, (3, 3), padding='same', activation=LeakyReLU())) # batch_size x 24 x 24 x 64\n",
    "generator.add(BatchNormalization())\n",
    "\n",
    "generator.add(Conv2DTranspose(1, (3, 3), padding='same', activation='tanh')) # batch_size x 24 x 24 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4416550c-fc72-43ca-bd04-5b7ca0ac10b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose (Conv2DTran (None, 24, 24, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 24, 24, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 24, 24, 8)         1160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 24, 24, 1)         73        \n",
      "=================================================================\n",
      "Total params: 99,745\n",
      "Trainable params: 99,569\n",
      "Non-trainable params: 176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa9a00a-557b-4236-9bf7-55c1726c4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(128, (3, 3), padding='same', input_shape=(24, 24, 1), activation=LeakyReLU()))\n",
    "discriminator.add(Conv2D(64, (3, 3), padding='same', activation=LeakyReLU()))\n",
    "discriminator.add(BatchNormalization())\n",
    "\n",
    "discriminator.add(Conv2D(32, (3, 3), padding='same', activation=LeakyReLU()))\n",
    "discriminator.add(Conv2D(16, (3, 3), padding='same', activation=LeakyReLU()))\n",
    "discriminator.add(BatchNormalization())\n",
    "\n",
    "discriminator.add(Conv2D(8, (3, 3), padding='same', activation=LeakyReLU()))\n",
    "discriminator.add(Dropout(0.2))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='tanh'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b5ac95-626d-4242-8302-c03a307ed1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 8)         1160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4609      \n",
      "=================================================================\n",
      "Total params: 104,249\n",
      "Trainable params: 104,089\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880e177c-2cf3-42d5-a9c2-f89aac3791fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = Sequential()\n",
    "discriminator.trainable = False\n",
    "gan.add(generator)\n",
    "gan.add(discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da39c332-9ac9-45a3-a3b5-1f88668063f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 24, 24, 1)         99745     \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 104249    \n",
      "=================================================================\n",
      "Total params: 203,994\n",
      "Trainable params: 99,569\n",
      "Non-trainable params: 104,425\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gan.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f8163f8-b132-4f85-a16f-4a7d4f9cafdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.085465044\n",
      "Discriminator Decision: Fake\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "choice = np.random.randint(0, 2)\n",
    "plt.figure(1)\n",
    "generated_image = None\n",
    "\n",
    "if choice == 0:\n",
    "    noise = tf.random.normal([1, 24, 24, 1])\n",
    "    generated_image = generator(noise, training=True)\n",
    "\n",
    "    plt.imshow(generated_image[0, :, :, 0]) # generate some noise to test the generator\n",
    "elif choice == 1:\n",
    "    randnum = np.random.randint(0, 60000)\n",
    "    generated_image = generator(smc2_trainset[randnum:randnum + 1], training=True)\n",
    "    plt.imshow(generated_image[0, :, :, 0])\n",
    "\n",
    "decision = discriminator(generated_image, training=False)\n",
    "decision = decision.numpy()[0][0]\n",
    "print(decision)\n",
    "\n",
    "if decision < 0:\n",
    "    print('Discriminator Decision: Fake') # test out discriminator. Outputs positive values for real and negative values for fake images\n",
    "elif decision >= 0:\n",
    "    print('Discriminator Decision: Real') # test out discriminator. Outputs positive values for real and negative values for fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c96d9bc2-5bc0-4ce3-918d-8a0461cac52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, labels, n_samples): # generate real samples with real labels\n",
    "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "\tX = dataset[ix]\n",
    "\ty = labels[ix]\n",
    "\treturn X, y\n",
    "\n",
    "def generate_fake_samples(n_samples): # generate fake samples with fake labels\n",
    "    noise = tf.random.normal([n_samples, 24, 24, 1])\n",
    "    X = generator(noise, training=False)\n",
    "    y = np.random.uniform(low=-1, high=0, size=n_samples)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ad6272-fb45-4e4d-90ae-2aa3ccc3ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, model, dataset, d_labels, n_samples):\n",
    "    X_real, y_real = generate_real_samples(dataset, d_labels, n_samples)\n",
    "    acc_real = model.evaluate(X_real, y_real)\n",
    "    \n",
    "    x_fake, y_fake = generate_fake_samples(n_samples)\n",
    "    acc_fake = model.evaluate(x_fake, y_fake)\n",
    "\n",
    "    print('Real Image Accuracy: {}%'.format(acc_real[1] * 100))\n",
    "    print('Fake Image Accuracy: {}%'.format(acc_fake[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73bab2ec-3bb6-43e5-a0e3-8c9eab5ffeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0bacf51-092e-446f-92e7-794be21cf98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gan_model, dataset, data_labels, n_epochs, n_batch):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, data_labels, half_batch)\n",
    "            d_loss1 = gan_model.train_on_batch(X_real, y_real)\n",
    "            d_loss1 = sum(d_loss1) / len(d_loss1)\n",
    "            \n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(half_batch)\n",
    "            d_loss2 = gan_model.train_on_batch(X_fake, y_fake)\n",
    "            d_loss2 = sum(d_loss2) / len(d_loss2)\n",
    "            \n",
    "            # prepare points in latent space as input for the generator\n",
    "            X_gan = tf.random.normal([n_batch, 24, 24, 1])\n",
    "            y_gan = np.random.uniform(low=0, high=1, size=n_batch)\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            g_loss = sum(g_loss) / len(g_loss)\n",
    "            # summarize loss on this batch\n",
    "        print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "        if (i+1) % 2 == 0:\n",
    "            summarize_performance(i, gan_model, dataset, data_labels, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e97777d1-99c9-4d29-a921-a58c97f44e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 10:55:16.182983: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-11 10:55:16.204362: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 600/600, d1=2.904, d2=-3.643 g=3.990\n",
      ">2, 600/600, d1=2.904, d2=-4.196 g=3.518\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.1416 - accuracy: 0.6667\n",
      "4/4 [==============================] - 0s 2ms/step - loss: -8.5700 - accuracy: 0.0000e+00\n",
      "Real Image Accuracy: 66.66666269302368%\n",
      "Fake Image Accuracy: 0.0%\n",
      ">3, 600/600, d1=2.904, d2=-4.001 g=4.016\n",
      ">4, 600/600, d1=2.904, d2=-4.105 g=3.982\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.1416 - accuracy: 0.6667\n",
      "4/4 [==============================] - 0s 2ms/step - loss: -7.9225 - accuracy: 0.0000e+00\n",
      "Real Image Accuracy: 66.66666269302368%\n",
      "Fake Image Accuracy: 0.0%\n",
      ">5, 600/600, d1=2.904, d2=-3.663 g=3.476\n",
      ">6, 600/600, d1=2.904, d2=-3.791 g=3.345\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.1416 - accuracy: 0.6667\n",
      "4/4 [==============================] - 0s 2ms/step - loss: -7.4085 - accuracy: 0.0000e+00\n",
      "Real Image Accuracy: 66.66666269302368%\n",
      "Fake Image Accuracy: 0.0%\n",
      ">7, 600/600, d1=2.904, d2=-4.030 g=3.887\n",
      ">8, 600/600, d1=2.904, d2=-3.859 g=4.046\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.1416 - accuracy: 0.6667\n",
      "4/4 [==============================] - 0s 2ms/step - loss: -7.7030 - accuracy: 0.0000e+00\n",
      "Real Image Accuracy: 66.66666269302368%\n",
      "Fake Image Accuracy: 0.0%\n",
      ">9, 600/600, d1=2.904, d2=-3.958 g=3.509\n",
      ">10, 600/600, d1=2.904, d2=-3.868 g=4.142\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.1416 - accuracy: 0.6667\n",
      "4/4 [==============================] - 0s 2ms/step - loss: -8.0278 - accuracy: 0.0000e+00\n",
      "Real Image Accuracy: 66.66666269302368%\n",
      "Fake Image Accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "train(gan, smc2_trainset, smc2_lt_onehot, epochs, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-CUDA11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
