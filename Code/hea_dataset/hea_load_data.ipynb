{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d8af29-d007-4208-8056-f0b345c67aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bc0979-7b80-4f69-bfa4-582472bce899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 28 11:54:20 2021: Initializing...\n",
      "(4000, 5)\n",
      "(1000, 5)\n",
      "Mon Jun 28 11:54:47 2021: Successfully loaded all data sets!\n"
     ]
    }
   ],
   "source": [
    "print(str(time.ctime()) + \": Initializing...\")\n",
    "dset_train = np.load('/gpfs/alpine/gen150/proj-shared/junqi/hea/HEA_train.npy')\n",
    "dset_val = np.load('/gpfs/alpine/gen150/proj-shared/junqi/hea/HEA_val.npy')\n",
    "lt = np.load('/gpfs/alpine/gen150/proj-shared/junqi/hea/label_T_train.npy')\n",
    "lv = np.load('/gpfs/alpine/gen150/proj-shared/junqi/hea/label_T_val.npy')\n",
    "\n",
    "# trainset, label_training = shuffle(trainset, label_training, random_state=0)\n",
    "# valset, label_validation = shuffle(valset, label_validation, random_state=0)\n",
    "\n",
    "train_size = 4000\n",
    "val_size = 1000\n",
    "\n",
    "trainset = dset_train[0:train_size]\n",
    "valset = dset_val[0:val_size]\n",
    "label_training = lt[0:train_size]\n",
    "label_validation = lv[0:val_size]\n",
    "\n",
    "lt_onehot = to_categorical(label_training) # make one hot vectors\n",
    "lv_onehot = to_categorical(label_validation)\n",
    "ltunique = np.unique(label_training).astype(int)\n",
    "lvunique = np.unique(label_validation).astype(int)\n",
    "\n",
    "lt_onehot = lt_onehot[:, ltunique]\n",
    "lv_onehot = lv_onehot[:, lvunique]\n",
    "print(lt_onehot.shape)\n",
    "print(lv_onehot.shape)\n",
    "\n",
    "print(str(time.ctime()) + \": Successfully loaded all data sets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ffffc4-3cc7-413e-a095-171e9e857c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('hea_dataset.npz', train=trainset, val=valset, ltoh=lt_onehot, lvoh=lv_onehot, labtrain=label_training, labval=label_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d8591-c0db-4cc2-9481-eba7742f7e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-CUDA11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
